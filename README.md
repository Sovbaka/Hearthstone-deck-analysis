Это проект, посвященный сборке и исследованию данных о популярности тех или иных колод в карточной игре Heartstone. 

Мы скачаем данные с сайта [HeartPwn](https://www.hearthpwn.com/), на котором пользователи могут делиться своими колодами. Также скачаем .json [файл](https://hearthstonejson.com/docs/cards.html), который послужит в качестве API для карт Hearthston-а. Посмотрим на "временные ряды", повизуализируем данные, увидим, как влияет выход новых карт на пользовательскую активность и сосздадим интеративне приложение streamlit. 

У читателя может возникнуть вопрос: почему если на сайте есть данные с 2013 по 2024 в работе присутствуют только данные с 2013 по 2015?
Отвечаю – не удалось реализовать способ быстрой загрузки с сайта, который бы потребовал ротацию ip, использование proxy или что-то в это духе, потому что при виде запросов с одого и того же адреса сайт очень активно кидает 429 error, в то время как скачать необходимо данные с ~675000 страниц.

В проекте использованы следующие технологии:

- работа с API (json)
- Веб-скреппинг с помощью BeautifulSoup4 и requests
- Обработка данных Pandas, в том числе оконные методы и группировки
- Регулярные выражения для некоторых случаев при скреппинге данных
- Визуализация данных, которая если и не сложная, то приятная глазу
- Приложение Streamlit, которое запускается (вот [видео](https://drive.google.com/file/d/1adAAO_PUg3Wq7X3SK_fbQUmq1AHCocyw/view?usp=sharing)) локально, но которое наотрез отказывается быть опубликованным, вероятно из-за того, что начинается его работа с прочтения одного гигабайта данных.

*Примечание:* github не отображает графики во второй части ноутбука Analitycs, но они видны, если его скачать (необязательно запускать)

«Описание применения генеративной модели»:
При работе были использованы генеративные модели Mistral AI и ChatGpt-4o. Способ применения: я задвал вопросы относительно того, как реализовать ту или иную идею (вопросы в основном касались синтаксиса), а также спрашивал совета по устранению ошибок.